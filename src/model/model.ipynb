{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../src/datasets/combined_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m         pickle\u001b[39m.\u001b[39mdump(nb_model, nb_file)\n\u001b[1;32m     35\u001b[0m \u001b[39m# Call the function to train and save the models\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m train_and_save_models()\n",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m, in \u001b[0;36mtrain_and_save_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_and_save_models\u001b[39m():\n\u001b[1;32m      2\u001b[0m     \u001b[39m# Load the dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     concatenated_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mpardir, \u001b[39m'\u001b[39;49m\u001b[39msrc\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdatasets\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcombined_data.csv\u001b[39;49m\u001b[39m'\u001b[39;49m))\u001b[39m.\u001b[39mdropna(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[39m# Initialize LabelEncoder\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     encoder \u001b[39m=\u001b[39m LabelEncoder()\n",
      "File \u001b[0;32m~/Desktop/star platinum/projects/olutomiwa/olu_proj/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Desktop/star platinum/projects/olutomiwa/olu_proj/lib/python3.9/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    620\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/star platinum/projects/olutomiwa/olu_proj/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Desktop/star platinum/projects/olutomiwa/olu_proj/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1879\u001b[0m     f,\n\u001b[1;32m   1880\u001b[0m     mode,\n\u001b[1;32m   1881\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1882\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1883\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1884\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1885\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1886\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1887\u001b[0m )\n\u001b[1;32m   1888\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/star platinum/projects/olutomiwa/olu_proj/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../src/datasets/combined_data.csv'"
     ]
    }
   ],
   "source": [
    "def train_and_save_models():\n",
    "    # Load the dataset\n",
    "    concatenated_data = pd.read_csv(os.path.join(os.path.pardir, 'src', 'datasets', 'combined_data.csv')).dropna(axis=1)\n",
    "\n",
    "    # Initialize LabelEncoder\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    # Apply label encoding to the \"prognosis\" column in the DataFrame\n",
    "    concatenated_data[\"prognosis\"] = encoder.fit_transform(concatenated_data[\"prognosis\"])\n",
    "\n",
    "    # Select features (X) and target variable (y)\n",
    "    X = concatenated_data.iloc[:, :-1]\n",
    "    y = concatenated_data.iloc[:, -1]\n",
    "\n",
    "    # Initialize models\n",
    "    rf_model = RandomForestClassifier(random_state=18)\n",
    "    svm_model = SVC(probability=True)\n",
    "    nb_model = GaussianNB()\n",
    "\n",
    "    # Train models on data\n",
    "    rf_model.fit(X, y)\n",
    "    svm_model.fit(X, y)\n",
    "    nb_model.fit(X, y)\n",
    "\n",
    "    # Save models to files\n",
    "    with open('rf_model.pkl', 'wb') as rf_file:\n",
    "        pickle.dump(rf_model, rf_file)\n",
    "\n",
    "    with open('svm_model.pkl', 'wb') as svm_file:\n",
    "        pickle.dump(svm_model, svm_file)\n",
    "\n",
    "    with open('nb_model.pkl', 'wb') as nb_file:\n",
    "        pickle.dump(nb_model, nb_file)\n",
    "\n",
    "# Call the function to train and save the models\n",
    "train_and_save_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df  = pd.read_csv(os.path.join(os.path.pardir, 'datasets', 'training.csv')).dropna(axis=1)\n",
    "test_df = pd.read_csv(os.path.join(os.path.pardir, 'datasets', 'testing.csv')).dropna(axis=1)\n",
    "\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# # Apply label encoding to the \"prognosis\" column in the DataFrame\n",
    "# concatenated_data[\"prognosis\"] = encoder.fit_transform(concatenated_data[\"prognosis\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([train_df,test_df]).to_csv('combined_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fungal infection\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global_encoder = encoder\n",
    "\n",
    "# Select features (X) and target variable (y)\n",
    "X = concatenated_data.iloc[:, :-1]\n",
    "y = concatenated_data.iloc[:, -1]\n",
    "\n",
    "# Initialize models\n",
    "rf_model = RandomForestClassifier(random_state=18)\n",
    "svm_model = SVC(probability=True)\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Train models on data\n",
    "rf_model.fit(X, y)\n",
    "svm_model.fit(X, y)\n",
    "nb_model.fit(X, y)\n",
    "\n",
    "\n",
    "# Save the trained models for future use\n",
    "# You may want to store them as files (pickle, joblib, etc.)\n",
    "    # For simplicity, let's assume they are stored as global variables\n",
    "    global_rf_model = rf_model\n",
    "    global_svm_model = svm_model\n",
    "    global_nb_model = nb_model\n",
    "\n",
    "    # Load the saved encoder and models in the prediction phase\n",
    "    def load_encoder_and_models():\n",
    "        # Load the encoder\n",
    "        loaded_encoder = global_encoder\n",
    "\n",
    "        # Load the models\n",
    "        loaded_rf_model = global_rf_model\n",
    "        loaded_svm_model = global_svm_model\n",
    "        loaded_nb_model = global_nb_model\n",
    "\n",
    "        return loaded_encoder, loaded_rf_model, loaded_svm_model, loaded_nb_model\n",
    "\n",
    "    # Load the saved encoder and models\n",
    "    loaded_encoder, loaded_rf_model, loaded_svm_model, loaded_nb_model = load_encoder_and_models()\n",
    "\n",
    "    # Define the symptom index dictionary and predictions classes\n",
    "    symptoms = X.columns.values\n",
    "    symptom_index = {symptom.capitalize(): index for index, symptom in enumerate(symptoms)}\n",
    "    predictions_classes = loaded_encoder.classes_\n",
    "\n",
    "    data_dict = {\n",
    "        \"symptom_index\": symptom_index,\n",
    "        \"predictions_classes\": predictions_classes\n",
    "    }\n",
    "\n",
    "    # Define the predictDisease function using the loaded encoder and models\n",
    "    def predictDisease(symptoms):\n",
    "        symptoms = symptoms.split(\",\")\n",
    "        # Creating input data for the models\n",
    "        input_data = [0] * len(data_dict[\"symptom_index\"])\n",
    "        for symptom in symptoms:\n",
    "            index = data_dict[\"symptom_index\"].get(symptom.capitalize(), -1)\n",
    "            if index != -1:\n",
    "                input_data[index] = 1\n",
    "\n",
    "        # Reshape the input data and convert it into a suitable format for model predictions\n",
    "        input_data = np.array(input_data).reshape(1, -1)\n",
    "\n",
    "        # Generate individual outputs\n",
    "        rf_prediction = data_dict[\"predictions_classes\"][loaded_rf_model.predict(input_data)[0]]\n",
    "        svm_prediction = data_dict[\"predictions_classes\"][loaded_svm_model.predict(input_data)[0]]\n",
    "        nb_prediction = data_dict[\"predictions_classes\"][loaded_nb_model.predict(input_data)[0]]\n",
    "        \n",
    "        all_predictions = [rf_prediction, svm_prediction, nb_prediction]\n",
    "        unique_predictions, counts = np.unique(all_predictions, return_counts=True)\n",
    "        final_prediction = unique_predictions[np.argmax(counts)]\n",
    "\n",
    "        # return final_prediction, final_probability\n",
    "        return  rf_prediction\n",
    "\n",
    "    # Define the final prediction function using the mode of all predictions\n",
    "    def getFinalPrediction(symptoms):\n",
    "        final_prediction = predictDisease(symptoms)\n",
    "        \n",
    "        # return final_prediction,final_probability*100 \n",
    "        return  final_prediction\n",
    "\n",
    "\n",
    "    # Testing the function\n",
    "    print(getFinalPrediction(\"small_dents_in_nails,nodal_skin_eruptions,,small_dents_in_nails\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['itching', 'skin_rash', 'nodal_skin_eruptions', 'continuous_sneezing',\n",
       "       'shivering', 'chills', 'joint_pain', 'stomach_pain', 'acidity',\n",
       "       'ulcers_on_tongue',\n",
       "       ...\n",
       "       'blackheads', 'scurring', 'skin_peeling', 'silver_like_dusting',\n",
       "       'small_dents_in_nails', 'inflammatory_nails', 'blister',\n",
       "       'red_sore_around_nose', 'yellow_crust_ooze', 'prognosis'],\n",
       "      dtype='object', length=133)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns\n",
    "\n",
    "concatenated_data[\"prognosis\"] = encoder.fit_transform(concatenated_data[\"prognosis\"])\n",
    "\n",
    "# Select features (X) and target variable (y)\n",
    "X = train_df.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Desktop/star platinum/projects/olutomiwa/olu_proj/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(model_dir,'encoder.pkl'), 'rb') as encoder:\n",
    "    loaded_encoder = pickle.load(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itching</th>\n",
       "      <th>skin_rash</th>\n",
       "      <th>nodal_skin_eruptions</th>\n",
       "      <th>continuous_sneezing</th>\n",
       "      <th>shivering</th>\n",
       "      <th>chills</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>stomach_pain</th>\n",
       "      <th>acidity</th>\n",
       "      <th>ulcers_on_tongue</th>\n",
       "      <th>...</th>\n",
       "      <th>pus_filled_pimples</th>\n",
       "      <th>blackheads</th>\n",
       "      <th>scurring</th>\n",
       "      <th>skin_peeling</th>\n",
       "      <th>silver_like_dusting</th>\n",
       "      <th>small_dents_in_nails</th>\n",
       "      <th>inflammatory_nails</th>\n",
       "      <th>blister</th>\n",
       "      <th>red_sore_around_nose</th>\n",
       "      <th>yellow_crust_ooze</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4915</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4916</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4917</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4918</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4919</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4920 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  \\\n",
       "0           1          1                     1                    0   \n",
       "1           0          1                     1                    0   \n",
       "2           1          0                     1                    0   \n",
       "3           1          1                     0                    0   \n",
       "4           1          1                     1                    0   \n",
       "...       ...        ...                   ...                  ...   \n",
       "4915        0          0                     0                    0   \n",
       "4916        0          1                     0                    0   \n",
       "4917        0          0                     0                    0   \n",
       "4918        0          1                     0                    0   \n",
       "4919        0          1                     0                    0   \n",
       "\n",
       "      shivering  chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  \\\n",
       "0             0       0           0             0        0                 0   \n",
       "1             0       0           0             0        0                 0   \n",
       "2             0       0           0             0        0                 0   \n",
       "3             0       0           0             0        0                 0   \n",
       "4             0       0           0             0        0                 0   \n",
       "...         ...     ...         ...           ...      ...               ...   \n",
       "4915          0       0           0             0        0                 0   \n",
       "4916          0       0           0             0        0                 0   \n",
       "4917          0       0           0             0        0                 0   \n",
       "4918          0       0           1             0        0                 0   \n",
       "4919          0       0           0             0        0                 0   \n",
       "\n",
       "      ...  pus_filled_pimples  blackheads  scurring  skin_peeling  \\\n",
       "0     ...                   0           0         0             0   \n",
       "1     ...                   0           0         0             0   \n",
       "2     ...                   0           0         0             0   \n",
       "3     ...                   0           0         0             0   \n",
       "4     ...                   0           0         0             0   \n",
       "...   ...                 ...         ...       ...           ...   \n",
       "4915  ...                   0           0         0             0   \n",
       "4916  ...                   1           1         1             0   \n",
       "4917  ...                   0           0         0             0   \n",
       "4918  ...                   0           0         0             1   \n",
       "4919  ...                   0           0         0             0   \n",
       "\n",
       "      silver_like_dusting  small_dents_in_nails  inflammatory_nails  blister  \\\n",
       "0                       0                     0                   0        0   \n",
       "1                       0                     0                   0        0   \n",
       "2                       0                     0                   0        0   \n",
       "3                       0                     0                   0        0   \n",
       "4                       0                     0                   0        0   \n",
       "...                   ...                   ...                 ...      ...   \n",
       "4915                    0                     0                   0        0   \n",
       "4916                    0                     0                   0        0   \n",
       "4917                    0                     0                   0        0   \n",
       "4918                    1                     1                   1        0   \n",
       "4919                    0                     0                   0        1   \n",
       "\n",
       "      red_sore_around_nose  yellow_crust_ooze  \n",
       "0                        0                  0  \n",
       "1                        0                  0  \n",
       "2                        0                  0  \n",
       "3                        0                  0  \n",
       "4                        0                  0  \n",
       "...                    ...                ...  \n",
       "4915                     0                  0  \n",
       "4916                     0                  0  \n",
       "4917                     0                  0  \n",
       "4918                     0                  0  \n",
       "4919                     1                  1  \n",
       "\n",
       "[4920 rows x 132 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olu_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a2d4cade14d351263a337c07585b9c8ef877f8121186e7e0f587eae719241fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
